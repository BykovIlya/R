c(mean(Bikes$cnt)-2*sd(Bikes$cnt),mean(Bikes$cnt)+2*sd(Bikes$cnt))
#Найдем все значения, не попадающие в данный промежуток
for (i in 1:length(Bikes$cnt))
if (findInterval(Bikes$cnt[i],c(mean(Bikes$cnt) - 2*sd(Bikes$cnt),mean(Bikes$cnt) + 2*sd(Bikes$cnt))) != 1)
twos[i] <- Bikes$cnt[i]
Вывод значений
paste(twos, collapse = ' ')
paste(twos, collapse = ' ')
c(mean(Bikes$cnt)-2*sd(Bikes$cnt),mean(Bikes$cnt)+2*sd(Bikes$cnt))
#Найдем все значения, не попадающие в данный промежуток
for (i in 1:length(Bikes$cnt))
if (findInterval(Bikes$cnt[i],c(mean(Bikes$cnt) - 2*sd(Bikes$cnt),mean(Bikes$cnt) + 2*sd(Bikes$cnt))) != 1)
twos[i] <- Bikes$cnt[i]
#Вывод значений
paste(twos, collapse = ' ')
c(mean(Bikes$cnt)-2*sd(Bikes$cnt),mean(Bikes$cnt)+2*sd(Bikes$cnt))
#Найдем все значения, не попадающие в данный промежуток
for (i in 1:length(Bikes$cnt)){
if (findInterval(Bikes$cnt[i],c(mean(Bikes$cnt) - 2*sd(Bikes$cnt),mean(Bikes$cnt) + 2*sd(Bikes$cnt))) != 1){
twos[i] <- Bikes$cnt[i]
}}
median <- median(bikes$cnt)
mad <- mad(Bikes$cnt)
c(median-3*mad,median+3*mad)
#Находим все значения, не принадлежащие данному интервалу
for (i in 1:length(bikes$cnt))
median <- median(Bikes$cnt)
mad <- mad(Bikes$cnt)
c(median-3*mad,median+3*mad)
#Находим все значения, не принадлежащие данному интервалу
for (i in 1:length(Bikes$cnt))
if (findInterval(Bikes$cnt[i],c(median-3*mad,median+3*mad)) != 1)
hampel[i] <- Bikes$cnt[i]
hampel<-hampel[!is.na(hampel)]
paste(hampel, collapse = ' ')
Bikes_85$resid <- resid(lm)
sd2 <- 2*sd(resid(lm))
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid)>sd2, 1, 0)
plot(Bikes_85$resid, col=Bikes_85$Outs+1, pch=16)
Bikes_85$resid <- resid(lm)
sd2 <- 2*sd(resid(lm))
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid)>sd2, 1, 0)
plot(Bikes_85$resid, col=Bikes_85$Outs+1, pch=16)
Bikes_85$resid <- resid(Bikes_reg_85)
sd2 <- 2*sd(resid(Bikes_reg_85))
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid)>sd2, 1, 0)
plot(Bikes_85$resid, col=Bikes_85$Outs+1, pch=16)
for (i in 1:length(Bikes$cnt))
if (findInterval(Bikes$cnt[i],c(median-3*mad,median+3*mad)) != 1)
hampel[i] <- Bikes$cnt[i]
hampel<-hampel[!is.na(hampel)]
paste(hampel, collapse = ' ')
Bikes_85$resid <- resid(Bikes_reg_85)
sd2 <- 2*sd(resid(Bikes_reg_85))
c(mean(Bikes$cnt)-2*sd(Bikes$cnt),mean(Bikes$cnt)+2*sd(Bikes$cnt))
#Найдем все значения, не попадающие в данный промежуток
for (i in 1:length(Bikes$cnt)){
if (findInterval(Bikes$cnt[i],c(mean(Bikes$cnt) - 2*sd(Bikes$cnt),mean(Bikes$cnt) + 2*sd(Bikes$cnt))) != 1){
twos[i] <- Bikes$cnt[i]
}}
paste(twos, collapse = ' ')
Bikes_85$resid2 <- resid(Bikes_reg_85)
sd2 <- 2*sd(resid(Bikes_reg_85))
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid2)>sd2, 1, 0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
# 3 сигм
Bikes_85$resid3 <- resid(Bikes_reg_85)
sd2 <- 2*sd(resid(Bikes_reg_85))
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid3)>sd2, 1, 0)
plot(Bikes_85$resid3, col=Bikes_85$Outs+1, pch=16)
Bikes_85$resid3 <- resid(Bikes_reg_85)
sd2 <- 2*sd(resid(Bikes_reg_85))
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid3)>sd2, 1, 0)
plot(Bikes_85$resid3, col=Bikes_85$Outs+1, pch=16)
Bikes_85$resid3 <- resid(Bikes_reg_85)
sd3 <- 3*sd(resid(Bikes_reg_85))
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid3)>sd3, 1, 0)
plot(Bikes_85$resid3, col=Bikes_85$Outs+1, pch=16)
median <- median(bikes$cnt)
mad <- mad(bikes$cnt)
c(median-3*mad,median+3*mad)
for (i in 1:length(bikes$cnt))
median <- median(Bikes$cnt)
mad <- mad(Bikes$cnt)
c(median-3*mad,median+3*mad)
median <- median(Bikes$cnt)
mad <- mad(Bikes$cnt)
c(median-3*mad,median+3*mad)
for (i in 1:length(Bikes$cnt))
if (findInterval(Bikes$cnt[i],c(median-3*mad,median+3*mad)) != 1)
hampel[i] <- Bikes$cnt[i]
hampel<-hampel[!is.na(hampel)]
paste(hampel, collapse = ' ')
median <- median(Bikes_85$resid2)
mad <- 3*mad
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid2)>median+mad, 1, 0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
Bikes_85$resid2 <- resid(Bikes_reg_85)
sd2 <- 2*sd(resid(Bikes_reg_85))
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid2)>sd2, 1, 0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
rm(mad, median)
median <- median(Bikes_85$resid2)
mad <- 3*mad
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid2)>median+mad, 1, 0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
median <- median(Bikes_85$resid2)
mad <- 3*mad
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid2)>median+mad, 1, 0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
median <- median(Bikes_85$resid2)
mad <- 3*mad
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid2)>median+mad, 1, 0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
#[mean – 2 * SD, mean + 2 * SD]
mad <- mad(Bikes_85$resid2)
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid2)>median+mad, 1, 0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
mad <- mad(Bikes_85$resid2)
Bikes_85$Outs<-ifelse(res<median-mad & res>median+mad,1,0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
median
mad
mad <- mad(Bikes_85$resid2)
Bikes_85$Outs<-ifelse(res<median-3*mad & res>median+3*mad,1,0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
mad <- mad(Bikes_85$resid2)
Bikes_85$Outs<-ifelse(Bikes_85$resid2<median-3*mad & Bikes_85$resid2>median+3*mad,1,0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
# "File" - "Reopen with encoding" - "UTF-8" - (Set as default) - OK
Sys.setenv(LANG = "en")
#Подключаем необходимые пакеты (нужно раскомментировать начало строки и установить пакеты, если этого не делалось когда-нибудь ранее)
#install.packages("ggplot2", dependencies = TRUE)
library(ggplot2)
#install.packages("Hmisc", dependencies = TRUE)
library(Hmisc)
#install.packages("corrgram", dependencies = TRUE)
library(corrgram)
#install.packages("car", dependencies = TRUE)
library("car")
#install.packages("lmtest", dependencies = TRUE)
library("lmtest")
#install.packages("outliers", dependencies = TRUE)
library("outliers")
#Считаем данные из файла:
Bikes <- read.csv(file="hour.csv", fileEncoding = "UTF8")
#Выведем переменные файла:
names(Bikes)
#Основные характеристики нормализованной температуры:
summary(Bikes$temp)
#Основные характеристики влажности:
summary(Bikes$hum)
#Основные статистики по скрости ветра:
summary(Bikes$windspeed)
#Характеристики часов наблюдений:
summary(Bikes$hr)
#Регулярное выражение для проверки пропущенных значений:
grep(TRUE, is.na(Bikes), fixed=FALSE)
#Построим гистограмму нормированной температуры:
ggplot(Bikes, aes(x=Bikes$temp, y=Bikes$cnt)) + geom_bar(stat="identity") + geom_vline(aes(xintercept=mean(Bikes$temp), color="red", linetype="dashed", size=1))
#Построим гистограмму описания влажности:
ggplot(Bikes, aes(x=Bikes$hum)) + geom_histogram(binwidth=.01, fill="white", colour="black")
#Построим гистограмму описания скорости ветра:
ggplot(Bikes, aes(x=Bikes$windspeed)) + geom_histogram(binwidth=.03, fill="white", colour="black")
#Диаграмма рассеивания для температуры и количества взятых в прокат велосипедов:
qplot(Bikes$cnt, Bikes$temp, xlab = "Количество велосипедов", ylab = "Температура", main = "Зависимость температуры и количества взятых в прокат велосипедов")
#Диаграмма рассеивания для влажности и количества взятых в прокат велосипедов:
qplot(Bikes$cnt, Bikes$hum, xlab = "Количество велосипедов", ylab = "Влажность", main = "Зависимость влажности и количества взятых в прокат велосипедов")
#Влияние погодных условий на количество взятых в прокат велосипедов:
boxplot(cnt ~ weathersit, data = Bikes, xlab = "Погодные условия", ylab = "Количество заказов", main = "Зависимость кол-ва заказов от погодных условий")
#Влияние времени дня на количество взятых в прокат велосипедов:
boxplot(cnt ~ factor(hr), data = Bikes, xlab='Час дня', ylab='Количество заказов')
#Влияние времени года на количество взятых в прокат велосипедов:
boxplot(cnt ~ season, data = Bikes,  xlab = "Сезон (весна, лето, осень, зима)", ylab =  "Количество велосипедов",  main = "Зависимость количества взятых велосипедов от времени года")
#Выявим степень зависимости между переменными:
#Функция построения матрицы Пирсона с уровнями значимости:
corstarsl <- function(x)
{
#Исходная матрица
x <- as.matrix(x)
R <- rcorr(x)$r
p <- rcorr(x)$P
#задание уровней значимости.
mystars <- ifelse(p < .001, "***", ifelse(p < .01, "** ", ifelse(p < .05, "* ", " ")))
#Округление значений матрицы до 2 знаков после запятой
R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1]
#Построение матрицы со значениями корреляции и уровнями значимости
Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x))
diag(Rnew) <- paste(diag(R), " ", sep="")
rownames(Rnew) <- colnames(x)
colnames(Rnew) <- paste(colnames(x), "", sep="")
#Удаление верхнего треугольника матрицы
Rnew <- as.matrix(Rnew)
Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
Rnew <- as.data.frame(Rnew)
#Удаление последней колонки ( так как она пуста ) и возврат готовой матрицы
Rnew <- cbind(Rnew[1:length(Rnew)-1])
return(Rnew)
}
#Выборка из 7 переменных для анализа взаимосвязей показателей с помощью матрицы Пирсона
x <- subset(Bikes, select = c("season","weathersit","temp","hum","windspeed","hr","cnt"));
#Вызов функции построения матрицы
corstarsl(data.matrix(x));
Bikes <- read.csv(file="hour.csv", fileEncoding = "UTF8")
#Функция построения матрицы Пирсона с уровнями значимости:
corstarsl <- function(x)
{
#Исходная матрица
x <- as.matrix(x)
R <- rcorr(x)$r
p <- rcorr(x)$P
#задание уровней значимости.
mystars <- ifelse(p < .001, "***", ifelse(p < .01, "** ", ifelse(p < .05, "* ", " ")))
#Округление значений матрицы до 2 знаков после запятой
R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1]
#Построение матрицы со значениями корреляции и уровнями значимости
Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x))
diag(Rnew) <- paste(diag(R), " ", sep="")
rownames(Rnew) <- colnames(x)
colnames(Rnew) <- paste(colnames(x), "", sep="")
#Удаление верхнего треугольника матрицы
Rnew <- as.matrix(Rnew)
Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
Rnew <- as.data.frame(Rnew)
#Удаление последней колонки ( так как она пуста ) и возврат готовой матрицы
Rnew <- cbind(Rnew[1:length(Rnew)-1])
return(Rnew)
}
#Выборка из 7 переменных для анализа взаимосвязей показателей с помощью матрицы Пирсона
x <- subset(Bikes, select = c("season","weathersit","temp","hum","windspeed","hr","cnt"));
#Вызов функции построения матрицы
corstarsl(data.matrix(x));
#Визуализируем матрицу корреляции пирсона
corrgram(x, order=NULL, lower.panel=panel.shade,  upper.panel=NULL, main="Визуализация корреляции Пирсона")
#Для последующей проверки модели мы разделили все имеющиеся данные в соотношении 85:15. То есть тестовыми данными мы сделаем 2 609 записей. Выберем их случайным образом из нашей выборки, пользуясь индексацией по переменной instanse (есть в исходных данных).
Bikes_15 <- Bikes[sample(1:nrow(Bikes), 2609, replace=FALSE),]
Bikes_85<-Bikes[!(Bikes$instant %in% Bikes_15$instant),]
Bikes_15 <- Bikes_15[order(Bikes_15$instant),]
Bikes_85 <- Bikes_85[order(Bikes_85$instant),]
rownames(Bikes_15)<-NULL
rownames(Bikes_85)<-NULL
#Построим пошагово (на основе AIC) линейную регрессию из имеющихся переменных (выкинули из анализа переменные, которые мало влияют на зависимую):
Bikes_reg_85 <- step(lm(cnt ~ temp + hum + factor(hr) + factor(season) + factor(weathersit), data = Bikes_85))
#Выведем основные характеристики полученной модели:
summary(Bikes_reg_85)
#Посмотрим графики, характеризующие построенную регрессию:
plot(Bikes_reg_85)
#Проведем формальный тест  Бройша — Пагана на выявление гетероскедастичности:
bptest(Bikes_reg_85)
#Проведем формальный тест Голдфелда — Куандта на выявление гетероскедастичности:
gqtest(Bikes_reg_85)
#Проведем дисперсионный анализ моделей:
reduced <- step(lm(cnt ~ temp + hum + factor(hr) + factor(season) + factor(weathersit), data = Bikes_85))
anova(reduced, Bikes_reg_85)
#Протестируем нашу модель на остальных переменных с 95% доверительным интервалом:
result <- predict(Bikes_reg_85,newdata=Bikes_15, interval='prediction', level=0.95)
Bikes_15$lwr_cnt <- result[,"lwr"]
Bikes_15$upr_cnt <- result[,"upr"]
Bikes_15$fit_cnt <- result[,"fit"]
#Для наглядности построим график испытаний на 20 измерениях:
plot(Bikes_15$temp,Bikes_15$cnt, xlab="temp",ylab = "cnt",ylim=c(0,20))
points(Bikes_15$temp,Bikes_15$fit_cnt, col="red")
#Вычислим среднюю относительную ошибку наших испытаний по всей выборке:
Bikes_15$fit_cnt <- ifelse(result[,"fit"]>0, result[,"fit"], 0);
mean(((abs(Bikes_15$cnt - Bikes_15$fit_cnt))/Bikes_15$cnt)*100)
#Выявим выбросы в данных в помощью теста Граббса:
grubbs.test(Bikes$cnt, type = 10, opposite = FALSE, two.sided = FALSE)
#Определим "нормальность" нашей выборки в помощью методов 2 и 3 сигм:
#Правило двух сигм
#[mean – 2 * SD, mean + 2 * SD]
Bikes_85$resid2 <- resid(Bikes_reg_85)
sd2 <- 2*sd(resid(Bikes_reg_85))
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid2)>sd2, 1, 0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
# 3 сигм
Bikes_85$resid3 <- resid(Bikes_reg_85)
sd3 <- 3*sd(resid(Bikes_reg_85))
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid3)>sd3, 1, 0)
plot(Bikes_85$resid3, col=Bikes_85$Outs+1, pch=16)
#Идентификатор
mad <- mad(Bikes_85$resid2)
Bikes_85$Outs<-ifelse(Bikes_85$resid2<median-3*mad & Bikes_85$resid2>median+3*mad,1,0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
#Очистим память от ненужных переменных:
rm(x, )
rm(x)
hr_factor <- function(time) { if (time > 22 || time < 5) return(0)  else if (time >= 5 && time < 9) return(1)   else if (time >= 9 && time <= 12) return(2)   else if (time > 12 && time <= 16) return(3)   else if (time > 16) return(4)}
bikes$newHr <- lapply(bikes$hr, hr_factor)
bikes$newHr <- unlist(bikes$newHr)
hr_factor <- function(time) { if (time > 22 || time < 5) return(0)  else if (time >= 5 && time < 9) return(1)   else if (time >= 9 && time <= 12) return(2)   else if (time > 12 && time <= 16) return(3)   else if (time > 16) return(4)}
bikes$newHr <- lapply(Bikes$hr, hr_factor)
bikes$newHr <- unlist(Bikes$newHr)
hr_factor <- function(time) { if (time > 22 || time < 5) return(0)  else if (time >= 5 && time < 9) return(1)   else if (time >= 9 && time <= 12) return(2)   else if (time > 12 && time <= 16) return(3)   else if (time > 16) return(4)}
bikes$newHr <- lapply(Bikes$hr, hr_factor)
Bikes$newHr <- lapply(Bikes$hr, hr_factor)
Bikes$newHr <- unlist(Bikes$newHr)
summary(Bikes_reg_85 <- rlm(cnt ~ temp +I(temp^2)+ hum + I(hum^2) + I(hum*temp) + factor(newHr) + factor(season) + factor(weathersit), data = Bikes_85))
install.packages("MASS", dependencies = TRUE)
install.packages("MASS", dependencies = TRUE)
library("MASS")
Bikes <- read.csv(file="hour.csv", fileEncoding = "UTF8")
#Выведем переменные файла:
corstarsl <- function(x)
{
#Исходная матрица
x <- as.matrix(x)
R <- rcorr(x)$r
p <- rcorr(x)$P
#задание уровней значимости.
mystars <- ifelse(p < .001, "***", ifelse(p < .01, "** ", ifelse(p < .05, "* ", " ")))
#Округление значений матрицы до 2 знаков после запятой
R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1]
#Построение матрицы со значениями корреляции и уровнями значимости
Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x))
diag(Rnew) <- paste(diag(R), " ", sep="")
rownames(Rnew) <- colnames(x)
colnames(Rnew) <- paste(colnames(x), "", sep="")
#Удаление верхнего треугольника матрицы
Rnew <- as.matrix(Rnew)
Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
Rnew <- as.data.frame(Rnew)
#Удаление последней колонки ( так как она пуста ) и возврат готовой матрицы
Rnew <- cbind(Rnew[1:length(Rnew)-1])
return(Rnew)
}
#Выборка из 7 переменных для анализа взаимосвязей показателей с помощью матрицы Пирсона
x <- subset(Bikes, select = c("season","weathersit","temp","hum","windspeed","hr","cnt"));
#Вызов функции построения матрицы
corstarsl(data.matrix(x));
#Визуализируем матрицу корреляции пирсона
corrgram(x, order=NULL, lower.panel=panel.shade,  upper.panel=NULL, main="Визуализация корреляции Пирсона")
#Для последующей проверки модели мы разделили все имеющиеся данные в соотношении 85:15. То есть тестовыми данными мы сделаем 2 609 записей. Выберем их случайным образом из нашей выборки, пользуясь индексацией по переменной instanse (есть в исходных данных).
Bikes_15 <- Bikes[sample(1:nrow(Bikes), 2609, replace=FALSE),]
Bikes_85<-Bikes[!(Bikes$instant %in% Bikes_15$instant),]
Bikes_15 <- Bikes_15[order(Bikes_15$instant),]
Bikes_85 <- Bikes_85[order(Bikes_85$instant),]
rownames(Bikes_15)<-NULL
rownames(Bikes_85)<-NULL
#Построим пошагово (на основе AIC) линейную регрессию из имеющихся переменных (выкинули из анализа переменные, которые мало влияют на зависимую):
Bikes_reg_85 <- step(lm(cnt ~ temp + hum + factor(hr) + factor(season) + factor(weathersit), data = Bikes_85))
install.packages("corrgram", dependencies = TRUE)
library("corrgram")
corrgram(x, order=NULL, lower.panel=panel.shade,  upper.panel=NULL, main="Визуализация корреляции Пирсона")
#Для последующей проверки модели мы разделили все имеющиеся данные в соотношении 85:15. То есть тестовыми данными мы сделаем 2 609 записей. Выберем их случайным образом из нашей выборки, пользуясь индексацией по переменной instanse (есть в исходных данных).
Bikes_15 <- Bikes[sample(1:nrow(Bikes), 2609, replace=FALSE),]
Bikes_85<-Bikes[!(Bikes$instant %in% Bikes_15$instant),]
Bikes_15 <- Bikes_15[order(Bikes_15$instant),]
Bikes_85 <- Bikes_85[order(Bikes_85$instant),]
rownames(Bikes_15)<-NULL
rownames(Bikes_85)<-NULL
#Построим пошагово (на основе AIC) линейную регрессию из имеющихся переменных (выкинули из анализа переменные, которые мало влияют на зависимую):
Bikes_reg_85 <- step(lm(cnt ~ temp + hum + factor(hr) + factor(season) + factor(weathersit), data = Bikes_85))
#Выведем основные характеристики полученной модели:
summary(Bikes_reg_85)
#Посмотрим графики, характеризующие построенную регрессию:
plot(Bikes_reg_85)
#Проведем формальный тест  Бройша — Пагана на выявление гетероскедастичности:
bptest(Bikes_reg_85)
#Проведем формальный тест Голдфелда — Куандта на выявление гетероскедастичности:
gqtest(Bikes_reg_85)
#Проведем дисперсионный анализ моделей:
reduced <- step(lm(cnt ~ temp + hum + factor(hr) + factor(season) + factor(weathersit), data = Bikes_85))
anova(reduced, Bikes_reg_85)
#Протестируем нашу модель на остальных переменных с 95% доверительным интервалом:
result <- predict(Bikes_reg_85,newdata=Bikes_15, interval='prediction', level=0.95)
Bikes_15$lwr_cnt <- result[,"lwr"]
library(ggplot2)
#install.packages("Hmisc", dependencies = TRUE)
library(Hmisc)
library(corrgram)
#install.packages("corrgram", dependencies = TRUE)
#install.packages("car", dependencies = TRUE)
library("car")
#install.packages("lmtest", dependencies = TRUE)
library("lmtest")
#install.packages("outliers", dependencies = TRUE)
library("outliers")
#install.packages("MASS", dependencies = TRUE)
library("MASS")
#install.packages("corrgram", dependencies = TRUE)
library("corrgram")
#Считаем данные из файла:
Bikes <- read.csv(file="hour.csv", fileEncoding = "UTF8")
corstarsl <- function(x)
{
#Исходная матрица
x <- as.matrix(x)
R <- rcorr(x)$r
p <- rcorr(x)$P
#задание уровней значимости.
mystars <- ifelse(p < .001, "***", ifelse(p < .01, "** ", ifelse(p < .05, "* ", " ")))
#Округление значений матрицы до 2 знаков после запятой
R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1]
#Построение матрицы со значениями корреляции и уровнями значимости
Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x))
diag(Rnew) <- paste(diag(R), " ", sep="")
rownames(Rnew) <- colnames(x)
colnames(Rnew) <- paste(colnames(x), "", sep="")
#Удаление верхнего треугольника матрицы
Rnew <- as.matrix(Rnew)
Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
Rnew <- as.data.frame(Rnew)
#Удаление последней колонки ( так как она пуста ) и возврат готовой матрицы
Rnew <- cbind(Rnew[1:length(Rnew)-1])
return(Rnew)
}
#Выборка из 7 переменных для анализа взаимосвязей показателей с помощью матрицы Пирсона
x <- subset(Bikes, select = c("season","weathersit","temp","hum","windspeed","hr","cnt"));
#Вызов функции построения матрицы
corstarsl(data.matrix(x));
#Визуализируем матрицу корреляции пирсона
corrgram(x, order=NULL, lower.panel=panel.shade,  upper.panel=NULL, main="Визуализация корреляции Пирсона")
#Для последующей проверки модели мы разделили все имеющиеся данные в соотношении 85:15. То есть тестовыми данными мы сделаем 2 609 записей. Выберем их случайным образом из нашей выборки, пользуясь индексацией по переменной instanse (есть в исходных данных).
Bikes_15 <- Bikes[sample(1:nrow(Bikes), 2609, replace=FALSE),]
Bikes_85<-Bikes[!(Bikes$instant %in% Bikes_15$instant),]
Bikes_15 <- Bikes_15[order(Bikes_15$instant),]
Bikes_85 <- Bikes_85[order(Bikes_85$instant),]
rownames(Bikes_15)<-NULL
rownames(Bikes_85)<-NULL
#Построим пошагово (на основе AIC) линейную регрессию из имеющихся переменных (выкинули из анализа переменные, которые мало влияют на зависимую):
Bikes_reg_85 <- step(lm(cnt ~ temp + hum + factor(hr) + factor(season) + factor(weathersit), data = Bikes_85))
#Выведем основные характеристики полученной модели:
summary(Bikes_reg_85)
#Посмотрим графики, характеризующие построенную регрессию:
plot(Bikes_reg_85)
#Проведем формальный тест  Бройша — Пагана на выявление гетероскедастичности:
bptest(Bikes_reg_85)
#Проведем формальный тест Голдфелда — Куандта на выявление гетероскедастичности:
gqtest(Bikes_reg_85)
#Проведем дисперсионный анализ моделей:
reduced <- step(lm(cnt ~ temp + hum + factor(hr) + factor(season) + factor(weathersit), data = Bikes_85))
anova(reduced, Bikes_reg_85)
#Протестируем нашу модель на остальных переменных с 95% доверительным интервалом:
result <- predict(Bikes_reg_85,newdata=Bikes_15, interval='prediction', level=0.95)
Bikes_15$lwr_cnt <- result[,"lwr"]
Bikes_15$upr_cnt <- result[,"upr"]
Bikes_15$fit_cnt <- result[,"fit"]
#Для наглядности построим график испытаний на 20 измерениях:
plot(Bikes_15$temp,Bikes_15$cnt, xlab="temp",ylab = "cnt",ylim=c(0,20))
points(Bikes_15$temp,Bikes_15$fit_cnt, col="red")
#Вычислим среднюю относительную ошибку наших испытаний по всей выборке:
Bikes_15$fit_cnt <- ifelse(result[,"fit"]>0, result[,"fit"], 0);
mean(((abs(Bikes_15$cnt - Bikes_15$fit_cnt))/Bikes_15$cnt)*100)
#Выявим выбросы в данных в помощью теста Граббса:
grubbs.test(Bikes$cnt, type = 10, opposite = FALSE, two.sided = FALSE)
#Определим "нормальность" нашей выборки в помощью методов 2 и 3 сигм:
#Правило двух сигм
#[mean – 2 * SD, mean + 2 * SD]
Bikes_85$resid2 <- resid(Bikes_reg_85)
sd2 <- 2*sd(resid(Bikes_reg_85))
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid2)>sd2, 1, 0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
# 3 сигм
Bikes_85$resid3 <- resid(Bikes_reg_85)
sd3 <- 3*sd(resid(Bikes_reg_85))
Bikes_85$Outs<-ifelse(abs(Bikes_85$resid3)>sd3, 1, 0)
plot(Bikes_85$resid3, col=Bikes_85$Outs+1, pch=16)
#Идентификатор
mad <- mad(Bikes_85$resid2)
Bikes_85$Outs<-ifelse(Bikes_85$resid2<median-3*mad & Bikes_85$resid2>median+3*mad,1,0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
# С помощью диаграммы Бокса - Вискера, можно определить 5 участков с похожей скоростью роста показателя cnt.
#На основании этих данных, переменная “час дня” была разделена на следующие пять групп:
mad <- mad(Bikes_85$resid2)
median <- median(Bikes_85$resid2)
Bikes_85$Outs<-ifelse(Bikes_85$resid2>median+3*mad | Bikes_85$resid2<median-3*mad, 1, 0)
plot(Bikes_85$resid2, col=Bikes_85$Outs+1, pch=16)
# С помощью диаграммы Бокса - Вискера, можно определить 5 участков с похожей скоростью роста показателя cnt.
#На основании этих данных, переменная “час дня” была разделена на следующие пять групп:
# 0 - ночь ( с 22 до 5)
# 1 - утро (с 5 до 9)
# 2 - полдень ( с 9 до 12)
# 3 - день ( с 12 до 16)
# 4 - вечер ( с 16 до 22)
hr_factor <- function(time) { if (time > 22 || time < 5) return(0)  else if (time >= 5 && time < 9) return(1)   else if (time >= 9 && time <= 12) return(2)   else if (time > 12 && time <= 16) return(3)   else if (time > 16) return(4)}
Bikes$newHr <- lapply(Bikes$hr, hr_factor)
Bikes$newHr <- unlist(Bikes$newHr)
#Построим первую Робастную регрессию (минимизация по абсолютной ошибке ):
summary(Bikes_reg_85 <- rlm(cnt ~ temp +I(temp^2)+ hum + I(hum^2) + I(hum*temp) + factor(newHr) + factor(season) + factor(weathersit), data = Bikes_85))
summary(Bikes_reg_85 <- rlm(cnt ~ temp +I(temp^2)+ hum + I(hum^2) + I(hum*temp) + factor(newHr) + factor(season) + factor(weathersit), data = Bikes_85))
View(Bikes)
View(Bikes_85)
Bike_85$newHr <- lapply(Bikes_85$hr, hr_factor)
Bike_15$newHr <- lapply(Bikes_15$hr, hr_factor)
Bikes_85$newHr <- lapply(Bikes_85$hr, hr_factor)
Bikes_15$newHr <- lapply(Bikes_15$hr, hr_factor)
Bikes_15$newHr <- unlist(Bikes_15$newHr)
Bikes_85$newHr <- unlist(Bikes_85$newHr)
#Построим первую Робастную регрессию (минимизация по абсолютной ошибке ):
summary(Bikes_reg_85 <- rlm(cnt ~ temp +I(temp^2)+ hum + I(hum^2) + I(hum*temp) + factor(newHr) + factor(season) + factor(weathersit), data = Bikes_85))
biweights <- data.frame(count = Bikes_85$cnt, temp = Bikes_85$temp, hum = Bikes_85$hum, hour = Bikes_85$hr, resid = Bikes_reg_85$resid, weight = Bikes_reg_85$w)
biweights2 <- biweights[order(Bikes_reg_85$w),]
biweights2[14000:14025, ]
Bikes_reg_85.bisquare <- rlm(cnt ~ temp +I(temp^2)+ hum + I(hum^2) + I(hum*temp) + factor(newHr) + factor(season) + factor(weathersit), data=Bikes_85, psi = psi.bisquare)
summary(Bikes_reg_85.bisquare)
summary( rlm(cnt ~ temp +I(temp^2)+ hum + I(hum^2) + I(hum*temp) + factor(newHr) + factor(season) + factor(weathersit), data=Bikes_85, psi = psi.bisquare))
Bikes_reg_85.bisquare <- rlm(cnt ~ temp +I(temp^2)+ hum + I(hum^2) + I(hum*temp) + factor(newHr) + factor(season) + factor(weathersit), data=Bikes_85, psi = psi.bisquare)
summary(Bikes_reg_85.bisquare)
rob_predicted <- predict(Bikes_reg_85.bisquare, Bikes_15)
#Прогнозирование линейной модели
lm_predicted <- predict(lm, Bikes_15)
lm_actuals_pred <- cbind(lm_predicted, Bikes_15$cnt)
Bikes_reg_85 <- step(lm(cnt ~ temp + hum + factor(newHr) + factor(season) + factor(weathersit), data = Bikes_85))
Bikes_reg_85.bisquare <- rlm(cnt ~ temp +I(temp^2)+ hum + I(hum^2) + I(hum*temp) + factor(newHr) + factor(season) + factor(weathersit), data=Bikes_85, psi = psi.bisquare)
summary(Bikes_reg_85.bisquare)
#Прогнозирование робастной модели
rob_predicted <- predict(Bikes_reg_85.bisquare, Bikes_15)
lm_predicted <- predict(Bikes_reg_85, Bikes_15)
lm_actuals_pred <- cbind(lm_predicted, Bikes_15$cnt)
rob_actuals_pred <- cbind(rob_predicted, Bikes_15$cnt)
mean(apply(lm_actuals_pred, 1, min)/ apply(lm_actuals_pred, 1, max))
mean(apply(rob_actuals_pred, 1, min)/ apply(rob_actuals_pred, 1, max))
