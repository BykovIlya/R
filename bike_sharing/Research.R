# Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return 
# back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return 
# back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of 
# over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, 
# environmental and health issues. 
# 
# Apart from interesting real world applications of bike sharing systems, the characteristics of data being generated by
# these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration
# of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into
# a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important
# events in the city could be detected via monitoring these data.
# 
# =========================================
#   Data Set
# =========================================
#   Bike-sharing rental process is highly correlated to the environmental and seasonal settings. For instance, weather conditions,
# precipitation, day of week, season, hour of the day, etc. can affect the rental behaviors. The core data set is related to  
# the two-year historical log corresponding to years 2011 and 2012 from Capital Bikeshare system, Washington D.C., USA which is 
# publicly available in http://capitalbikeshare.com/system-data. We aggregated the data on two hourly and daily basis and then 
# extracted and added the corresponding weather and seasonal information. Weather information are extracted from http://www.freemeteo.com. 



# if you see KRAKOZYABRY then do 
# "File" - "Reopen with encoding" - "UTF-8" - (Set as default) - OK
Sys.setenv(LANG = "en")

#Подключаем необходимые пакеты (нужно раскомментировать начало строки и установить пакеты, если этого не делалось когда-нибудь ранее)
#install.packages("ggplot2", dependencies = TRUE)
library("ggplot2")
#install.packages("Hmisc", dependencies = TRUE)
library("Hmisc") 
#install.packages("corrgram", dependencies = TRUE)
library("corrgram")
#install.packages("car", dependencies = TRUE)
library("car")
#install.packages("lmtest", dependencies = TRUE)
library("lmtest")
#install.packages("outliers", dependencies = TRUE)
library("outliers")
#install.packages("MASS", dependencies = TRUE)
library("MASS")
#install.packages("corrgram", dependencies = TRUE)
library("corrgram")





#Считаем данные из файла:
Bikes <- read.csv(file="hour.csv", fileEncoding = "UTF8")

#Выведем переменные файла:
names(Bikes)

#Основные характеристики нормализованной температуры:
summary(Bikes$temp)

#Основные характеристики влажности:
summary(Bikes$hum)

#Основные статистики по скрости ветра:
summary(Bikes$windspeed)

#Характеристики часов наблюдений:
summary(Bikes$hr)

#Регулярное выражение для проверки пропущенных значений:
grep(TRUE, is.na(Bikes), fixed=FALSE)

#Построим гистограмму нормированной температуры:
ggplot(Bikes, aes(x=Bikes$temp, y=Bikes$cnt)) + geom_bar(stat="identity") + geom_vline(aes(xintercept=mean(Bikes$temp), color="red", linetype="dashed", size=1)) 

#Построим гистограмму описания влажности:
ggplot(Bikes, aes(x=Bikes$hum)) + geom_histogram(binwidth=.01, fill="white", colour="black")

#Построим гистограмму описания скорости ветра:
ggplot(Bikes, aes(x=Bikes$windspeed)) + geom_histogram(binwidth=.03, fill="white", colour="black")

#Диаграмма рассеивания для температуры и количества взятых в прокат велосипедов: 
qplot(Bikes$cnt, Bikes$temp, xlab = "Количество велосипедов", ylab = "Температура", main = "Зависимость температуры и количества взятых в прокат велосипедов")

#Диаграмма рассеивания для влажности и количества взятых в прокат велосипедов:
qplot(Bikes$cnt, Bikes$hum, xlab = "Количество велосипедов", ylab = "Влажность", main = "Зависимость влажности и количества взятых в прокат велосипедов")

#Влияние погодных условий на количество взятых в прокат велосипедов:
boxplot(cnt ~ weathersit, data = Bikes, xlab = "Погодные условия", ylab = "Количество заказов", main = "Зависимость кол-ва заказов от погодных условий")
  
#Влияние времени дня на количество взятых в прокат велосипедов:
boxplot(cnt ~ factor(hr), data = Bikes, xlab='Час дня', ylab='Количество заказов')

#Влияние времени года на количество взятых в прокат велосипедов:
boxplot(cnt ~ season, data = Bikes,  xlab = "Сезон (весна, лето, осень, зима)", ylab =  "Количество велосипедов",  main = "Зависимость количества взятых велосипедов от времени года")


#Выявим степень зависимости между переменными:
#Функция построения матрицы Пирсона с уровнями значимости:
corstarsl <- function(x)
  { 
#Исходная матрица
x <- as.matrix(x) 
R <- rcorr(x)$r 
p <- rcorr(x)$P 
  
#задание уровней значимости. 
mystars <- ifelse(p < .001, "***", ifelse(p < .01, "** ", ifelse(p < .05, "* ", " ")))
  
#Округление значений матрицы до 2 знаков после запятой
R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1] 
  
#Построение матрицы со значениями корреляции и уровнями значимости
Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x)) 
diag(Rnew) <- paste(diag(R), " ", sep="") 
rownames(Rnew) <- colnames(x) 
colnames(Rnew) <- paste(colnames(x), "", sep="") 
  
 #Удаление верхнего треугольника матрицы
Rnew <- as.matrix(Rnew)
Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
Rnew <- as.data.frame(Rnew) 
  
 #Удаление последней колонки ( так как она пуста ) и возврат готовой матрицы
Rnew <- cbind(Rnew[1:length(Rnew)-1])
return(Rnew) 
}

#Выборка из 7 переменных для анализа взаимосвязей показателей с помощью матрицы Пирсона
x <- subset(Bikes, select = c("season","weathersit","temp","hum","windspeed","hr","cnt")); 

#Вызов функции построения матрицы
corstarsl(data.matrix(x));

#Визуализируем матрицу корреляции пирсона
corrgram(x, order=NULL, lower.panel=panel.shade,  upper.panel=NULL, main="Визуализация корреляции Пирсона")




#Для последующей проверки модели мы разделили все имеющиеся данные в соотношении 85:15. То есть тестовыми данными мы сделаем 2 609 записей. Выберем их случайным образом из нашей выборки, пользуясь индексацией по переменной instanse (есть в исходных данных).

Bikes_15 <- Bikes[sample(1:nrow(Bikes), 2609, replace=FALSE),]
Bikes_85<-Bikes[!(Bikes$instant %in% Bikes_15$instant),]
Bikes_15 <- Bikes_15[order(Bikes_15$instant),]
Bikes_85 <- Bikes_85[order(Bikes_85$instant),]
rownames(Bikes_15)<-NULL
rownames(Bikes_85)<-NULL



#Построим пошагово (на основе AIC) линейную регрессию из имеющихся переменных (выкинули из анализа переменные, которые мало влияют на зависимую):
Bikes_reg_85 <- step(lm(cnt ~ temp + hum + factor(hr) + factor(season) + factor(weathersit), data = Bikes_85))

#Выведем основные характеристики полученной модели:
summary(Bikes_reg_85)

#Посмотрим графики, характеризующие построенную регрессию:
plot(Bikes_reg_85)


#Попробуем выявить ситуацию выcокой корреляции между независимыми переменными (мультиколлинеарность) для последующего исключения их из модели:
vif(Bikes_reg_85)

#Построим пошагово полиноминальную квадратичную множественную регрессию:
Bikes_reg_85 <- step(lm(cnt ~ temp +I(temp^2)+ hum + I(hum^2) + I(hum*temp) + factor(hr) + factor(season) + factor(weathersit), data = Bikes_85))

#Проведем формальный тест  Бройша — Пагана на выявление гетероскедастичности:
bptest(Bikes_reg_85)


#Проведем формальный тест Голдфелда — Куандта на выявление гетероскедастичности:
gqtest(Bikes_reg_85)

#Проведем дисперсионный анализ моделей:
reduced <- step(lm(cnt ~ temp + hum + factor(hr) + factor(season) + factor(weathersit), data = Bikes_85))
anova(reduced, Bikes_reg_85)

#Протестируем нашу модель на остальных переменных с 95% доверительным интервалом:
result <- predict(Bikes_reg_85,newdata=Bikes_15, interval='prediction', level=0.95)

Bikes_15$lwr_cnt <- result[,"lwr"]
Bikes_15$upr_cnt <- result[,"upr"]
Bikes_15$fit_cnt <- result[,"fit"]

#Для наглядности построим график испытаний на 20 измерениях:
plot(Bikes_15$temp,Bikes_15$cnt, xlab="temp",ylab = "cnt",ylim=c(0,20))
points(Bikes_15$temp,Bikes_15$fit_cnt, col="red")

#Вычислим среднюю относительную ошибку наших испытаний по всей выборке:
Bikes_15$fit_cnt <- ifelse(result[,"fit"]>0, result[,"fit"], 0);
mean(((abs(Bikes_15$cnt - Bikes_15$fit_cnt))/Bikes_15$cnt)*100)

#Выявим выбросы в данных в помощью теста Граббса:
grubbs.test(Bikes$cnt, type = 10, opposite = FALSE, two.sided = FALSE)

#выведем значения остатков
Bikes_85$resid <- resid(Bikes_reg_85)

#Определим "нормальность" нашей выборки в помощью методов 2 и 3 сигм:
#Правило двух сигм  
#[mean – 2 * SD, mean + 2 * SD]

#среднее
mean<-mean(Bikes_85$resid)

#два отклонения
sd2 <- 2*sd(Bikes_85$resid)

Bikes_85$OutsSd2<-ifelse(Bikes_85$resid<mean-sd2 | Bikes_85$resid>mean+sd2, 1, 0)
plot(Bikes_85$resid, col=Bikes_85$OutsSd2+1, pch=16)

# 3 сигм
sd3 <- 3*sd(Bikes_85$resid)
Bikes_85$OutsSd3<-ifelse(Bikes_85$resid<mean-sd3 | Bikes_85$resid>mean+sd3, 1, 0)
plot(Bikes_85$resid, col=Bikes_85$OutsSd3+1, pch=16)

#Идентификатор Hampel
mad <- mad(Bikes_85$resid)
median <- median(Bikes_85$resid)
Bikes_85$Outs<-ifelse(Bikes_85$resid>median+3*mad | Bikes_85$resid<median-3*mad, 1, 0)
plot(Bikes_85$resid, col=Bikes_85$Outs+1, pch=16)

# С помощью диаграммы Бокса - Вискера, можно определить 5 участков с похожей скоростью роста показателя cnt. 
#На основании этих данных, переменная “час дня” была разделена на следующие пять групп:
# 0 - ночь ( с 22 до 5)
# 1 - утро (с 5 до 9)
# 2 - полдень ( с 9 до 12)
# 3 - день ( с 12 до 16)
# 4 - вечер ( с 16 до 22)
hr_factor <- function(time) { if (time > 22 || time < 5) return(0)  else if (time >= 5 && time < 9) return(1)   else if (time >= 9 && time <= 12) return(2)   else if (time > 12 && time <= 16) return(3)   else if (time > 16) return(4)}
Bikes_85$newHr <- lapply(Bikes_85$hr, hr_factor)
Bikes_15$newHr <- lapply(Bikes_15$hr, hr_factor)
Bikes_15$newHr <- unlist(Bikes_15$newHr)
Bikes_85$newHr <- unlist(Bikes_85$newHr)

Bikes_reg_85 <- step(lm(cnt ~ temp + hum + factor(newHr) + factor(season) + factor(weathersit), data = Bikes_85))
#Построим наилучшую робастную регрессию и выведем ее основные характеристики: 
# Теперь, давайте построим эту же модель, но в этот раз используя 
# функцию bisquare (“Метод наименьших квадратов” с весовыми коэффициентами) взвешивания.
Bikes_reg_85.bisquare <- rlm(cnt ~ temp +I(temp^2)+ hum + I(hum^2) + I(hum*temp) + factor(newHr) + factor(season) + factor(weathersit), data=Bikes_85, psi = psi.bisquare)
summary(Bikes_reg_85.bisquare)

#Прогнозирование робастной модели
rob_predicted <- predict(Bikes_reg_85.bisquare, Bikes_15)

#Прогнозирование линейной модели
lm_predicted <- predict(Bikes_reg_85, Bikes_15)

lm_actuals_pred <- cbind(lm_predicted, Bikes_15$cnt)
rob_actuals_pred <- cbind(rob_predicted, Bikes_15$cnt)


mean(apply(lm_actuals_pred, 1, min)/ apply(lm_actuals_pred, 1, max))

mean(apply(rob_actuals_pred, 1, min)/ apply(rob_actuals_pred, 1, max))







